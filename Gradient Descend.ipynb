{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.29.1'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "n_state = env.observation_space.shape[0]\n",
    "n_action = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "weight = torch.rand(n_state, n_action)\n",
    "total_reward = 0\n",
    "terminated = False\n",
    "truncated = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, weight):\n",
    "    state, info = env.reset()\n",
    "    grads = []\n",
    "    total_reward = 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    while not (terminated or truncated):\n",
    "       state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "       z= torch.matmul(state, weight)\n",
    "       probs=torch.nn.Softmax()(z)\n",
    "       action = int(torch.bernoulli(probs[1]).item())\n",
    "       d_softmax = torch.diag(probs) - probs.view(-1, 1) * probs\n",
    "       d_log = d_softmax[action] / probs[action]\n",
    "       grad = state.view(-1, 1) * d_log\n",
    "       grads.append(grad)\n",
    "       state, reward, terminated, truncated, _ = env.step(action)\n",
    "       total_reward += reward \n",
    "       if (terminated or truncated): \n",
    "          break\n",
    "       return total_reward, grads\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episode = 1000\n",
    "weight = torch.rand(n_state, n_action)\n",
    "total_rewards = []\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[359], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_episode):\n\u001b[1;32m----> 2\u001b[0m     total_reward, gradients \u001b[38;5;241m=\u001b[39m \u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mЭпизод \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, total_reward))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, gradient \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(gradients):\n",
      "Cell \u001b[1;32mIn[355], line 11\u001b[0m, in \u001b[0;36mrun_episode\u001b[1;34m(env, weight)\u001b[0m\n\u001b[0;32m      9\u001b[0m z\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(state, weight)\n\u001b[0;32m     10\u001b[0m probs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSoftmax()(z)\n\u001b[1;32m---> 11\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mbernoulli(\u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     12\u001b[0m d_softmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(probs) \u001b[38;5;241m-\u001b[39m probs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m probs\n\u001b[0;32m     13\u001b[0m d_log \u001b[38;5;241m=\u001b[39m d_softmax[action] \u001b[38;5;241m/\u001b[39m probs[action]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "for episode in range(n_episode):\n",
    "    total_reward, gradients = run_episode(env, weight)\n",
    "    print('Эпизод {}: {}'.format(episode + 1, total_reward))\n",
    "    for i, gradient in enumerate(gradients):\n",
    "        weight += learning_rate * gradient * (total_reward - i)\n",
    "    total_rewards.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs=\n",
      " tensor([[0.5017, 0.4983]])\n",
      "action: 0\n",
      "torch.diag(probs):\n",
      " tensor([0.5017])\n",
      "d_softmax=\n",
      " tensor([[0.2500, 0.2517],\n",
      "        [0.2517, 0.2533]])\n",
      "probs.view(-1, 1)=\n",
      " tensor([[0.5017],\n",
      "        [0.4983]])\n",
      "probs.view(-1, 1) * probs=\n",
      " tensor([[0.2517, 0.2500],\n",
      "        [0.2500, 0.2483]])\n",
      "d_log=\n",
      " tensor([0.4983, 0.5050])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z= torch.matmul(state, weight)\n",
    "probs = torch.nn.Softmax()(z)\n",
    "print(\"probs=\\n\",probs)\n",
    "\n",
    "action = int(torch.bernoulli(probs[0,0]).item()) \n",
    "#action = int(torch.bernoulli(probs[1]).item()) - если сделать как в нижке, то падает\n",
    "print(\"action:\",action)\n",
    "\n",
    "d_softmax = torch.diag(probs) - probs.view(-1, 1) * probs\n",
    "d_log = d_softmax[action] / probs[action]\n",
    "\n",
    "print(\"torch.diag(probs):\\n\", torch.diag(probs))\n",
    "print(\"d_softmax=\\n\", d_softmax)\n",
    "print(\"probs.view(-1, 1)=\\n\", probs.view(-1, 1))\n",
    "print(\"probs.view(-1, 1) * probs=\\n\", probs.view(-1, 1) * probs)\n",
    "print(\"d_log=\\n\", d_log)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z= tensor([[0.0077, 0.0010]])\n",
      "probs= tensor([[0.5017, 0.4983]])\n"
     ]
    }
   ],
   "source": [
    "probs=torch.nn.Softmax()(z)\n",
    "print('z=',z)\n",
    "print('probs=',probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5063, 0.4937])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5063, 0.4937]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.bernoulli(probs[1]).item()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=torch.tensor([[2,1], \n",
    "                [3,0],\n",
    "                [4,2],\n",
    "                [1,1]])\n",
    "S= torch.tensor([[3,2,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W= tensor([[2, 1],\n",
      "        [3, 0],\n",
      "        [4, 2],\n",
      "        [1, 1]])\n",
      "S= tensor([[3, 2, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "print(\"W=\",W)\n",
    "print(\"S=\",S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18,  7]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(S,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
